{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from transformers import logging\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = CLIPModel.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
    "# processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151277313\n"
     ]
    }
   ],
   "source": [
    "print(model.num_parameters()) # 427616513 params for large-patch14\n",
    "                              # 151277313 params for base-patch32\n",
    "                              # 149620737 params for base-patch16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # boilerplate code from huggingface docs\n",
    "# url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "# image = Image.open(requests.get(url, stream=True).raw)\n",
    "# plt.imshow(image)\n",
    "# inputs = processor(text=[\"a photo of a cat\", \"a photo of a dog\"], images=image, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "# outputs = model(**inputs)\n",
    "# logits_per_image = outputs.logits_per_image # this is the image-text similarity score\n",
    "# probs = logits_per_image.softmax(dim=1) # we can take the softmax to get the label probabilities\n",
    "# print(outputs.text_embeds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extra_img:  890.jpg\n"
     ]
    }
   ],
   "source": [
    "# Loading data\n",
    "caption_path = \"/Users/echen/Desktop/CSE_6242.nosync/caption-contest-data/summaries\"\n",
    "cartoon_path = \"/Users/echen/Desktop/CSE_6242.nosync/caption-contest-data/cartoons\"\n",
    "ids = set()\n",
    "cap_paths = []\n",
    "img_paths = []\n",
    "for file in os.listdir(caption_path):\n",
    "    file_path = os.path.join(caption_path, file)\n",
    "    if not os.path.isfile(file_path) or file[-3:]!='csv' or file[:3] in ids:\n",
    "        continue\n",
    "    ids.add(file[:3])\n",
    "    cap_paths.append(file_path)\n",
    "for file in os.listdir(cartoon_path):\n",
    "    file_path = os.path.join(cartoon_path, file)\n",
    "    if not os.path.isfile(file_path) or file[-3:]!='jpg':\n",
    "        continue\n",
    "    if file[:3] not in ids: \n",
    "        print(\"extra_img: \", file)\n",
    "        continue\n",
    "    img_paths.append(file_path)\n",
    "id_list = list(ids)\n",
    "id_list.sort()\n",
    "cap_paths.sort()\n",
    "img_paths.sort()\n",
    "assert(len(img_paths) == len(cap_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca = PCA(n_components=50)\n",
    "# condensed_data = pca.fit_transform(img1_cap)\n",
    "# print(condensed_data.shape, np.max(condensed_data), np.min(condensed_data))\n",
    "# tsne = TSNE()\n",
    "# tsne_embeds = tsne.fit_transform(condensed_data)\n",
    "# norm_tsne_embeds = np.zeros(tsne_embeds.shape)\n",
    "# mins = np.min(tsne_embeds, axis=0, keepdims=True)\n",
    "# maxes = np.max(tsne_embeds, axis=0, keepdims=True)\n",
    "# norm_tsne_embeds = (tsne_embeds-mins)/(maxes-mins)\n",
    "# print(norm_tsne_embeds.shape, np.max(norm_tsne_embeds), np.min(norm_tsne_embeds))\n",
    "# print(norm_tsne_embeds[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TSNE Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeds(model, image, caption_list):\n",
    "    inputs = processor(text=caption_list, images=image, return_tensors=\"pt\", padding=True)\n",
    "    outputs = model(**inputs)\n",
    "    text_embeds = outputs.text_embeds.detach().numpy()\n",
    "    img_embeds = outputs.image_embeds.detach().numpy()\n",
    "    return text_embeds, img_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=50)\n",
    "tsne = TSNE()\n",
    "def get_tsne_embeds(img_df):\n",
    "    caps = img_df[\"cap_feat\"]\n",
    "    cap_data = np.vstack(caps)\n",
    "    condensed_data = pca.fit_transform(cap_data)\n",
    "    tsne_embeds = tsne.fit_transform(condensed_data)\n",
    "    norm_tsne_embeds = np.zeros(tsne_embeds.shape)\n",
    "    mins = np.min(tsne_embeds, axis=0, keepdims=True)\n",
    "    maxes = np.max(tsne_embeds, axis=0, keepdims=True)\n",
    "    norm_tsne_embeds = (tsne_embeds-mins)/(maxes-mins)\n",
    "    norm_tsne_embeds_df = pd.DataFrame({'X': norm_tsne_embeds[:,0], 'Y': norm_tsne_embeds[:,1], \"caption\": caps})\n",
    "    return norm_tsne_embeds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "def get_embeds_from_path(img_id, img_path, cap_path, batch_size=32):\n",
    "    df_list = []\n",
    "    img = Image.open(img_path)\n",
    "    inputs = processor(text=['test'], images=img, return_tensors=\"pt\", padding=True)\n",
    "    img_feat = model(**inputs).image_embeds.detach().numpy()\n",
    "    cap_csv = pd.read_csv(cap_path)\n",
    "    cap_csv[\"img_id\"] = img_id\n",
    "    cap_csv[\"cap_feat\"] = None\n",
    "    cap_csv[\"img_feat\"] = [img_feat]*len(cap_csv.index)\n",
    "    caption_list = []\n",
    "    for idx,row in cap_csv.iterrows():\n",
    "        caption_list.append(row['caption'])\n",
    "        if (idx == (len(cap_csv.index)-1)):\n",
    "            text_embeds, _ = get_embeds(model, img, caption_list)\n",
    "            for i,embed in enumerate(text_embeds):\n",
    "                cap_csv.at[idx-len(text_embeds)+1+i,\"cap_feat\"] = text_embeds[i]\n",
    "            caption_list = []\n",
    "        if (len(caption_list) != batch_size):continue\n",
    "        text_embeds, _ = get_embeds(model, img, caption_list)\n",
    "        for i,embed in enumerate(text_embeds):\n",
    "            cap_csv.at[idx-batch_size+1+i,\"cap_feat\"] = text_embeds[i]\n",
    "        caption_list = []\n",
    "    df_list.append(cap_csv)\n",
    "    return pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_columns = [\"caption\", \"img_id\", \"mean\",\"votes\"]\n",
    "def process_dataset_tsne(id_list, img_paths, cap_paths):\n",
    "    tsne_list = []\n",
    "    cap_list = []\n",
    "    for img_id, img_path, cap_path in zip(id_list, img_paths, cap_paths):\n",
    "        # process for TSNE data\n",
    "\n",
    "        img_df = get_embeds_from_path(img_id, img_path, cap_path)\n",
    "        tsne_feats = get_tsne_embeds(img_df)\n",
    "        tsne_feats[\"img_id\"] = img_id\n",
    "        tsne_list.append(tsne_feats)\n",
    "\n",
    "        # save complete dataset\n",
    "        cap_csv = pd.read_csv(cap_path)\n",
    "        cap_csv[\"img_id\"] = img_id\n",
    "        cap_list.append(cap_csv[relevant_columns])\n",
    "        # break\n",
    "\n",
    "    return pd.concat(tsne_list), pd.concat(cap_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create complete TSNE DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>caption</th>\n",
       "      <th>img_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.472153</td>\n",
       "      <td>0.110353</td>\n",
       "      <td>[-0.0024316842, 0.015905969, 0.011368003, 0.01...</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.601796</td>\n",
       "      <td>0.318031</td>\n",
       "      <td>[0.013644679, -0.013433615, 0.018261917, -0.00...</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.194784</td>\n",
       "      <td>0.741925</td>\n",
       "      <td>[0.013936422, 0.0062422995, -0.026340615, 0.00...</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.402756</td>\n",
       "      <td>0.582557</td>\n",
       "      <td>[0.024949286, 0.017259136, 0.012959481, -0.016...</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.438213</td>\n",
       "      <td>0.649546</td>\n",
       "      <td>[0.017066555, 0.027702762, -0.015552031, -0.02...</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          X         Y                                            caption  \\\n",
       "0  0.472153  0.110353  [-0.0024316842, 0.015905969, 0.011368003, 0.01...   \n",
       "1  0.601796  0.318031  [0.013644679, -0.013433615, 0.018261917, -0.00...   \n",
       "2  0.194784  0.741925  [0.013936422, 0.0062422995, -0.026340615, 0.00...   \n",
       "3  0.402756  0.582557  [0.024949286, 0.017259136, 0.012959481, -0.016...   \n",
       "4  0.438213  0.649546  [0.017066555, 0.027702762, -0.015552031, -0.02...   \n",
       "\n",
       "  img_id  \n",
       "0    510  \n",
       "1    510  \n",
       "2    510  \n",
       "3    510  \n",
       "4    510  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsne_df, condensed_cap_df = process_dataset_tsne(id_list, img_paths, cap_paths)\n",
    "tsne_df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In terms of preprocessing, we will likely want to save the original dataset dataframes without the precison or score breakdown columns. The TSNE dataframe above can be saved as is since it should be possible to filter for the correct img_id when necessary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caption</th>\n",
       "      <th>img_id</th>\n",
       "      <th>mean</th>\n",
       "      <th>votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm a congressman--obstruction is my job.</td>\n",
       "      <td>510</td>\n",
       "      <td>1.913043</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm what they mean when they say, 'The middle ...</td>\n",
       "      <td>510</td>\n",
       "      <td>1.842105</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Does this suit make me look flat?</td>\n",
       "      <td>510</td>\n",
       "      <td>1.711111</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When the right woman comes along, I'll know it.</td>\n",
       "      <td>510</td>\n",
       "      <td>1.625000</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I used to lie in the gutter, but then I quit d...</td>\n",
       "      <td>510</td>\n",
       "      <td>1.617647</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             caption img_id      mean  votes\n",
       "0          I'm a congressman--obstruction is my job.    510  1.913043     69\n",
       "1  I'm what they mean when they say, 'The middle ...    510  1.842105     19\n",
       "2                  Does this suit make me look flat?    510  1.711111     45\n",
       "3    When the right woman comes along, I'll know it.    510  1.625000     32\n",
       "4  I used to lie in the gutter, but then I quit d...    510  1.617647     34"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condensed_cap_df.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NewYorker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
